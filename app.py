import streamlit as st
import requests
import os
import zipfile
from io import BytesIO
from PIL import Image
from urllib.parse import quote

# ğŸ”‘ API í‚¤ ì„¤ì •
UNSPLASH_KEY = "j5lyiOKj0bj6iMFPgvCnO0cCB_eWEyx5NsXZr3VRR94"
PIXABAY_KEY = "51462455-6f4af1014e035b145b2e7731b"
KOGOL_KEY = "NBzHjXyev6wbzDaiuwiq+/U4WpluDs7pZypSHayREgTmJo32rmlp5ssiFGnUlZvFH1u+S3YjH7jJv+3w7eFNUg=="

DOWNLOAD_DIR = "images"
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

# ğŸ”½ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
def download_image(url, save_path):
    try:
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            with open(save_path, 'wb') as f:
                f.write(response.content)
            return True
    except Exception:
        pass
    return False

# ğŸ–¼ Unsplash ê²€ìƒ‰
def search_unsplash(keyword, count):
    st.markdown("### ğŸŸ¦ Unsplash")
    headers = {"Authorization": f"Client-ID {UNSPLASH_KEY}"}
    params = {"query": keyword, "per_page": count}
    try:
        r = requests.get("https://api.unsplash.com/search/photos", headers=headers, params=params, timeout=10)
        if r.status_code == 200:
            results = r.json().get("results", [])
            for i in range(0, len(results), 5):
                cols = st.columns(5)
                for j in range(5):
                    if i + j < len(results):
                        url = results[i + j]["urls"]["regular"]
                        path = os.path.join(DOWNLOAD_DIR, f"unsplash_{i + j + 1}.jpg")
                        if download_image(url, path):
                            cols[j].image(path, use_column_width="always", caption=f"Unsplash #{i + j + 1}")
    except Exception:
        st.warning("ğŸ”¸ Unsplashì—ì„œ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ğŸ–¼ Pixabay ê²€ìƒ‰
def search_pixabay(keyword, count):
    st.markdown("### ğŸŸ¨ Pixabay")
    try:
        r = requests.get(f"https://pixabay.com/api/?key={PIXABAY_KEY}&q={quote(keyword)}&per_page={count}", timeout=10)
        if r.status_code == 200:
            results = r.json().get("hits", [])
            for i in range(0, len(results), 5):
                cols = st.columns(5)
                for j in range(5):
                    if i + j < len(results):
                        url = results[i + j]["largeImageURL"]
                        path = os.path.join(DOWNLOAD_DIR, f"pixabay_{i + j + 1}.jpg")
                        if download_image(url, path):
                            cols[j].image(path, use_column_width="always", caption=f"Pixabay #{i + j + 1}")
    except Exception:
        st.warning("ğŸ”¸ Pixabayì—ì„œ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ğŸ–¼ Pexels ê²€ìƒ‰
def search_pexels(keyword, count):
    st.markdown("### ğŸŸ© Pexels")
    headers = {"Authorization": os.getenv("PEXELS_KEY", ""), "User-Agent": "Mozilla/5.0"}
    if not headers["Authorization"]:
        headers["Authorization"] = PEXELS_KEY  # fallback

    try:
        r = requests.get("https://api.pexels.com/v1/search", headers=headers, params={"query": keyword, "per_page": count}, timeout=10)
        if r.status_code == 200:
            photos = r.json().get("photos", [])
            for i in range(0, len(photos), 5):
                cols = st.columns(5)
                for j in range(5):
                    if i + j < len(photos):
                        url = photos[i + j]["src"]["original"]
                        path = os.path.join(DOWNLOAD_DIR, f"pexels_{i + j + 1}.jpg")
                        if download_image(url, path):
                            cols[j].image(path, use_column_width="always", caption=f"Pexels #{i + j + 1}")
    except Exception:
        st.warning("ğŸ”¸ Pexelsì—ì„œ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ğŸ–¼ ê³µê³µëˆ„ë¦¬ ê²€ìƒ‰
def search_kogol(keyword, count):
    st.markdown("### ğŸŸ¥ ê³µê³µëˆ„ë¦¬(KOGOL)")
    url = f"http://api.kogl.or.kr/search/portalDataSearch.do?ServiceKey={KOGOL_KEY}&pageNo=1&pageSize={count}&query={quote(keyword)}&sort=score&license=ko&format=json"
    try:
        r = requests.get(url, timeout=10)
        if r.status_code == 200:
            items = r.json().get("result", {}).get("items", [])
            for i in range(0, len(items), 5):
                cols = st.columns(5)
                for j in range(5):
                    if i + j < len(items):
                        item = items[i + j]
                        img_url = item.get("imageUrl", "")
                        if not img_url:
                            continue
                        path = os.path.join(DOWNLOAD_DIR, f"kogol_{i + j + 1}.jpg")
                        if download_image(img_url, path):
                            cols[j].image(path, use_column_width="always", caption=f"KOGOL #{i + j + 1}")
    except Exception:
        st.warning("ğŸ”¸ ê³µê³µëˆ„ë¦¬ì—ì„œ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ğŸ“¦ ë‹¤ìš´ë¡œë“œ zip ìƒì„±
def create_zip():
    zip_path = os.path.join(DOWNLOAD_DIR, "images.zip")
    with zipfile.ZipFile(zip_path, 'w') as zipf:
        for filename in os.listdir(DOWNLOAD_DIR):
            if filename.endswith(".jpg"):
                zipf.write(os.path.join(DOWNLOAD_DIR, filename), arcname=filename)
    return zip_path

# ğŸŒ Streamlit UI
st.title("ğŸ” ì´ë¯¸ì§€ ë©€í‹° ê²€ìƒ‰ ì•±")
keyword = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ (ì˜ˆ: ì œì£¼ì˜¤ë¦„)", value="ì œì£¼ì˜¤ë¦„")
count = st.slider("ì´ë¯¸ì§€ ê°œìˆ˜ (APIë³„)", min_value=5, max_value=30, step=5, value=10)

if st.button("ê²€ìƒ‰ ì‹œì‘"):
    # ê¸°ì¡´ ì´ë¯¸ì§€ ì‚­ì œ
    for f in os.listdir(DOWNLOAD_DIR):
        file_path = os.path.join(DOWNLOAD_DIR, f)
        if os.path.isfile(file_path):
            os.remove(file_path)

    with st.spinner("ì´ë¯¸ì§€ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
        search_unsplash(keyword, count)
        search_pixabay(keyword, count)
        search_pexels(keyword, count)
        search_kogol(keyword, count)

    zip_path = create_zip()
    with open(zip_path, "rb") as f:
        st.download_button(label="ğŸ“¦ ì´ë¯¸ì§€ ZIP ë‹¤ìš´ë¡œë“œ", data=f, file_name="images.zip", mime="application/zip")
